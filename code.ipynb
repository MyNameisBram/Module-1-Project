{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries I will be using \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline \n",
    "\n",
    "#pulling database and converting csv file to a pandas DataFrame in order to manipulate data effectively and effeciently \n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "#checking data\n",
    "df.head()\n",
    "\n",
    "#checking data types\n",
    "df.info()\n",
    "\n",
    "#checking for null values \n",
    "df.isna().sum()\n",
    "\n",
    "#replacing null values \n",
    "#replacing null values with zero inorder to clean column  \n",
    "df['yr_renovated'] = df['yr_renovated'].fillna(value=0)\n",
    "\n",
    "#replaced null values with zero because we don't have a record showing the house had any prior views. \n",
    "df['view'] = df['view'].fillna(value=0)\n",
    "\n",
    "#replaced null values with zero because this was a categorical data.\n",
    "df['waterfront'] = df.waterfront.fillna(value=0)\n",
    "\n",
    "#slicing rows in 'sqft_basement' that contains '?' in the values\n",
    "df = df[df.sqft_basement != '?']\n",
    "df.head(12)\n",
    "#checking work\n",
    "df.sqft_basement.value_counts()\n",
    "\n",
    "# #checking for unqiue items in large null value columns \n",
    "print('waterfront:' ,df.waterfront.unique())\n",
    "print('view:' , df.view.unique())\n",
    "print('yr_renovated:' , df.yr_renovated.unique())\n",
    "\n",
    "#converting data types\n",
    "#sqft_basement, convert data type into an interger \n",
    "df.sqft_basement = df.sqft_basement.astype('float64')\n",
    "df.waterfront = df.waterfront.astype('int64')\n",
    "df.info()\n",
    "\n",
    "#removing outlier in column 'bedrooms' \n",
    "df = df.drop(df[df.bedrooms >15].index)\n",
    "df.bedrooms.value_counts()\n",
    "\n",
    "#checking for general distribution \n",
    "df.hist(figsize= (30,25));\n",
    "\n",
    "#checking to see which predictors are the most correlated to price \n",
    "df.corr().head(20)\n",
    "\n",
    "#Dealing with outliers in two of the top three predictors \n",
    "df_one = df.drop(df[df.sqft_living > 8500].index)\n",
    "df_one = df.drop(df[df.sqft_above > 8000].index)\n",
    "\n",
    "#Dropping predictors lower than 10% correlation with 'price'\n",
    "#columns dropped: ['sqft_lot', 'condition', 'yr_built','zipcode', 'long', 'sqft_lot15']\n",
    "df_one = df.drop(['sqft_lot', 'condition', 'yr_built','zipcode', 'long', 'sqft_lot15'], axis = 1)\n",
    "\n",
    "#Heatamp to visualize correleation of df_one \n",
    "\n",
    "# Set the style of the visualization\n",
    "sns.set()\n",
    "\n",
    "# Create a covariance matrix\n",
    "corr = df_one.corr()\n",
    "\n",
    "# Generate a mask the size of our covariance matrix\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(12, 150, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "#checking for linearity assumptions between predictors and targets in df_one \n",
    "for i in ['bedrooms', 'bathrooms', 'sqft_living', 'floors','waterfront', 'view', 'grade', 'sqft_above', 'sqft_basement' ,'yr_renovated', 'lat', 'sqft_living15']:\n",
    "    sns.jointplot(x = i, y= 'price', data = df_one, kind= 'reg' ,label= i)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_one' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b5390fd1c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_one\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpred_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'~'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpred_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_one' is not defined"
     ]
    }
   ],
   "source": [
    "#Running an OLS rergression \n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols \n",
    "\n",
    "outcome = 'price'\n",
    "predictors = df_one.drop(['price', 'date'], axis=1)\n",
    "pred_sum = \"+\".join(predictors.columns)\n",
    "formula = outcome + '~' + pred_sum \n",
    "\n",
    "model = ols(formula= formula, data=df_one).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
